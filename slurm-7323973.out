/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:34302'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:42174'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:39830'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:40867'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:34958'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:37819'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:42943'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:44326'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:46054'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:33387'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:36525'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:45161'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:35390'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:33616'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:43011'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:43932'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:43984'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:33039'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:41545'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:32853'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:38205'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:43781'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:38741'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:43587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:46369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:36499'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:43142'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.171:34518'
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-umro0o9q', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-z5qfcnl9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-afhw1bz6', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-n2l_umme', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-w7aopwp0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ppap_dxm', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-hg9vf4zq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-w61inchz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-g2vra1wl', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-co9yy2z5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xqxuc4n7', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-46i8n4rt', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qov4cheo', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-403pjh5g', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1msw8x0y', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2ca_6sgb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-io_87vx5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-od_l4gj2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l134lbdf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-boweysld', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6fb4umwv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bauiqj86', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zoymes8k', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7qhntifd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jyyjfjml', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nlc5v77j', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-lig_rn2s', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:44958
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:32898
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:44958
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:37378
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:32898
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:45828
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:42931
distributed.worker - INFO -          dashboard at:         172.30.8.171:39123
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:37378
distributed.worker - INFO -          dashboard at:         172.30.8.171:46274
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:45828
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:42931
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:36173
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -          dashboard at:         172.30.8.171:44479
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.30.8.171:34259
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.30.8.171:38111
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:39331
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:36173
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:43135
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:46276
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:39331
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:38075
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:42380
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:46276
distributed.worker - INFO -          dashboard at:         172.30.8.171:36369
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:43135
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.30.8.171:45519
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:46184
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:39211
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:         172.30.8.171:35979
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:38075
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_ca4uj6i
distributed.worker - INFO -          dashboard at:         172.30.8.171:35792
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:46184
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:39211
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:32890
distributed.worker - INFO -          dashboard at:         172.30.8.171:37468
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zc770ngm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.30.8.171:45886
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l5lhnt0z
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:32890
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.30.8.171:33647
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_w6q7c94
distributed.worker - INFO -          dashboard at:         172.30.8.171:38816
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j4zlsh4t
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:42380
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jzds91x6
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tfx97kl3
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:         172.30.8.171:39504
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_4_4h4u8
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-b1wr9qbs
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vp2jfvz8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j5v654uu
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r967hlx1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-x8kg0jqd
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-adq6hkyd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:35676
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:42751
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:35676
distributed.worker - INFO -          dashboard at:         172.30.8.171:45524
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:42751
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -          dashboard at:         172.30.8.171:43644
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:41548
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:41548
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:35993
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:42587
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:37849
distributed.worker - INFO -          dashboard at:         172.30.8.171:40062
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:35993
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:42587
distributed.worker - INFO -          dashboard at:         172.30.8.171:45228
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:37849
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zr88b0gr
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -          dashboard at:         172.30.8.171:39765
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6tgo850m
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:40004
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4sjqou75
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:40004
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:         172.30.8.171:34100
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-c7w05ojq
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:39139
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:39139
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-h60kddt4
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:         172.30.8.171:36777
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:42082
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-llecj3ms
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:42082
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:35373
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:40397
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:35373
distributed.worker - INFO -          dashboard at:         172.30.8.171:35403
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:40397
distributed.worker - INFO -          dashboard at:         172.30.8.171:40133
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         172.30.8.171:34773
distributed.worker - INFO -          dashboard at:         172.30.8.171:42081
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4qpcuvty
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sty0rzj3
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-cdfud6c9
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kctn9hot
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-z_mkac4j
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:45517
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:45517
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:43595
distributed.worker - INFO -          dashboard at:         172.30.8.171:33342
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.171:34900
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:34900
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:         172.30.8.171:36764
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-buyqfuca
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-be36l4fz
distributed.worker - INFO -          Listening to:   tcp://172.30.8.171:43595
distributed.worker - INFO -          dashboard at:         172.30.8.171:41561
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r7_xi0ga
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.4:37359
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.utils_perf - INFO - full garbage collection released 47.74 MB from 473 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 15.82 MB from 438 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 39.61 MB from 463 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 383.49 MB from 489 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[-2.21738815e-02, -1.60188675e-02, -8.32939148e-03, ...,
         -8.02459717e-02, -5.37290573e-02, -4.72307205e-02],
        [-1.60427094e-02, -1.21288300e-02, -4.32968140e-03, ...,
         -1.12038612e-01, -8.51898193e-02, -5.46188354e-02],
        [-9.99736786e-03, -8.97121429e-03, -2.18200684e-03, ...,
         -7.51953125e-02, -4.84094620e-02,  4.16660309e-03],
        ...,
        [ 1.57018805e+00,  1.57101011e+00,  1.57210636e+00, ...,
          2.67864895e+00,  2.67541504e+00,  2.66635990e+00],
        [ 1.68298101e+00,  1.68509865e+00,  1.68785381e+00, ...,
          2.89841557e+00,  2.89986420e+00,  2.88609600e+00],
        [-6.74443913e+00, -6.74408007e+00, -6.74306679e+00, ...,
         -1.13544807e+01, -1.13505936e+01, -1.13457899e+01]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9db14400>, (slice(3, 4, None), slice(4000, 4729, None), slice(5000, 6000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[ 4.62287521,  5.16818047,  5.63899803, ..., -0.02383423,
         -0.01766586, -0.01360893],
        [ 3.12841415,  3.53010368,  3.87781906, ..., -0.01975441,
         -0.01418686, -0.01278496],
        [ 1.92282486,  2.21364021,  2.50393867, ..., -0.01604652,
         -0.01244354, -0.01426125],
        ...,
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3aabaa3e48>, (slice(9, 10, None), slice(2000, 3000, None), slice(6000, 7000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[-0.00494671, -0.00215816,  0.00038052, ...,         nan,
                 nan,         nan],
        [-0.00087547,  0.00217438,  0.00450134, ...,         nan,
                 nan,         nan],
        [ 0.00401688,  0.00628471,  0.00739288, ...,         nan,
                 nan,         nan],
        ...,
        [-0.02802372, -0.02055264, -0.01689053, ..., -0.02122021,
         -0.04981899, -0.08089542],
        [-0.02073574, -0.01783848, -0.01391411, ..., -0.04315853,
         -0.06879711, -0.11629581],
        [-0.01382637, -0.0128212 , -0.00905895, ..., -0.04697037,
         -0.06820488, -0.11923695]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a86eb3f28>, (slice(9, 10, None), slice(3000, 4000, None), slice(5000, 6000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[-0.06584358, -0.05757141, -0.04546165, ..., -0.02353859,
         -0.01955032, -0.01315498],
        [-0.04956436, -0.03790283, -0.02331161, ..., -0.02573204,
         -0.02213287, -0.01617813],
        [-0.0153904 , -0.00160027,  0.01159096, ..., -0.02905083,
         -0.02525711, -0.01931572],
        ...,
        [ 0.03786659,  0.04472733,  0.04460335, ..., -0.01096916,
         -0.02768326, -0.04357338],
        [ 0.05011749,  0.05939102,  0.0604744 , ..., -0.00129318,
         -0.01857758, -0.03572273],
        [ 0.04092598,  0.0531292 ,  0.06177139, ...,  0.00790024,
         -0.00938225, -0.02702332]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9f958da0>, (slice(1, 2, None), slice(1000, 2000, None), slice(3000, 4000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[14.04977036, 12.15724087, 10.31295204, ...,         nan,
                 nan,         nan],
        [14.99220753, 13.4264946 , 11.67599201, ...,         nan,
                 nan,         nan],
        [16.11496258, 14.77165413, 13.15139294, ...,         nan,
                 nan,         nan],
        ...,
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9e3d15f8>, (slice(21, 22, None), slice(3000, 4000, None), slice(8000, 8354, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9dcaacf8>, (slice(15, 16, None), slice(4000, 4729, None), slice(7000, 8000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9ea94940>, (slice(21, 22, None), slice(3000, 4000, None), slice(0, 1000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[-2.24055920e+01, -2.24062119e+01, -2.24067822e+01, ...,
         -2.20142326e+01, -2.20140438e+01, -2.20142612e+01],
        [ 5.15565491e+00,  5.15579224e+00,  5.15597916e+00, ...,
          5.03857231e+00,  5.03751564e+00,  5.03900528e+00],
        [ 4.46055222e+00,  4.46066284e+00,  4.46079445e+00, ...,
          4.35638046e+00,  4.35599899e+00,  4.35654068e+00],
        ...,
        [ 9.13810730e-03,  7.93457031e-03,  5.02014160e-03, ...,
         -3.64303589e-03, -5.27572632e-03, -8.92257690e-03],
        [ 1.44672394e-02,  7.90405273e-03,  7.20977783e-04, ...,
         -2.71415710e-03, -3.99398804e-03, -6.86645508e-03],
        [ 1.19209290e-03, -7.75527954e-03, -1.50470734e-02, ...,
         -2.57873535e-03, -3.49044800e-03, -5.11550903e-03]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9dedcef0>, (slice(22, 23, None), slice(0, 1000, None), slice(3000, 4000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[ 0.02929832,  0.03015509,  0.0294391 , ...,  0.01362038,
          0.00813484,  0.00117874],
        [ 0.03812453,  0.03737699,  0.03473332, ...,  0.01363754,
          0.00885391,  0.00239754],
        [ 0.02530395,  0.02440638,  0.02228429, ...,  0.01472282,
          0.01021767,  0.00393677],
        ...,
        [        nan,         nan,         nan, ..., -0.03383064,
         -0.03190422, -0.02883148],
        [        nan,         nan,         nan, ..., -0.03503799,
         -0.03612709, -0.03665733],
        [        nan,         nan,         nan, ..., -0.03224945,
         -0.03386116, -0.03532982]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9db5aa58>, (slice(1, 2, None), slice(1000, 2000, None), slice(1000, 2000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[-2.58617401e-02, -2.20680237e-02, -1.42364502e-02, ...,
                     nan,             nan,             nan],
        [-2.77748108e-02, -2.51178741e-02, -1.79080963e-02, ...,
                     nan,             nan,             nan],
        [-2.87513733e-02, -2.71339417e-02, -2.08606720e-02, ...,
                     nan,             nan,             nan],
        ...,
        [-1.34521284e+01,  9.99650860e+00,  8.00909233e+00, ...,
                     nan,             nan,             nan],
        [-1.27546253e+01, -1.47749548e+01,  8.64087486e+00, ...,
                     nan,             nan,             nan],
        [-1.18937197e+01,  1.13957043e+01,  9.50038242e+00, ...,
                     nan,             nan,             nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9f5c60b8>, (slice(15, 16, None), slice(2000, 3000, None), slice(8000, 8354, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        ...,
        [-0.46404234, -0.44513056, -0.40387619, ...,  0.01542854,
          0.00971222,  0.00366402],
        [-0.18179075, -0.17082848, -0.15138435, ...,  0.01567459,
          0.00951385,  0.00271416],
        [-0.0312428 , -0.02654743, -0.02061527, ...,  0.01481819,
          0.00873184,  0.00162315]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3aae133710>, (slice(2, 3, None), slice(0, 1000, None), slice(1000, 2000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[ -0.02558899,  -0.02514458,  -0.02021027, ...,          nan,
                  nan,          nan],
        [ -0.02622032,  -0.02653885,  -0.02282143, ...,          nan,
                  nan,          nan],
        [ -0.02639198,  -0.02711678,  -0.02457428, ...,          nan,
                  nan,          nan],
        ...,
        [-13.07388401,   9.69054317,   7.21293831, ...,          nan,
                  nan,          nan],
        [-12.39070034, -14.35241222,   8.24100304, ...,          nan,
                  nan,          nan],
        [-11.55023766,  11.1313343 ,   9.15816307, ...,          nan,
                  nan,          nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3aa49008d0>, (slice(19, 20, None), slice(2000, 3000, None), slice(8000, 8354, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[ 8.08105469e-02,  5.95264435e-02,  4.90970612e-02, ...,
          3.10014153e+00,  3.59720039e+00,  4.11074448e+00],
        [ 8.24546814e-02,  5.09738922e-02,  2.97641754e-02, ...,
          1.95171928e+00,  2.31973648e+00,  2.71652985e+00],
        [ 7.65953064e-02,  3.18260193e-02,  1.22909546e-02, ...,
          1.08898926e+00,  1.35378838e+00,  1.63673782e+00],
        ...,
        [-9.86480713e-03, -8.18538666e-03, -7.54833221e-03, ...,
                     nan,             nan,             nan],
        [-8.84342194e-03, -7.34329224e-03, -6.47068024e-03, ...,
                     nan,             nan,             nan],
        [-7.42626190e-03, -5.46360016e-03, -3.60584259e-03, ...,
                     nan,             nan,             nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9d5ade10>, (slice(9, 10, None), slice(2000, 3000, None), slice(5000, 6000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        ...,
        [-0.46527576, -0.44631454, -0.40495113, ...,  0.01567268,
          0.00996971,  0.00394821],
        [-0.18227562, -0.17128432, -0.1517885 , ...,  0.0157547 ,
          0.00944138,  0.00252724],
        [-0.03132786, -0.02661984, -0.02067166, ...,  0.01465988,
          0.00844383,  0.00117683]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9ec8d6d8>, (slice(1, 2, None), slice(0, 1000, None), slice(1000, 2000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        ...,
        [-0.01939964, -0.0174427 , -0.02092361, ..., -0.01874352,
         -0.01756668, -0.01338959],
        [-0.01673698, -0.01766396, -0.02319527, ..., -0.02097893,
         -0.02122879, -0.01835442],
        [-0.01523781, -0.01904488, -0.02564621, ..., -0.02287102,
         -0.02422142, -0.02274895]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a86e872e8>, (slice(10, 11, None), slice(1000, 2000, None), slice(7000, 8000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        ...,
        [-0.02025223, -0.01818466, -0.02082825, ..., -0.01819992,
         -0.01902771, -0.01707649],
        [-0.01716042, -0.01789474, -0.02266884, ..., -0.01932526,
         -0.02122879, -0.02082634],
        [-0.01542854, -0.0188427 , -0.02463341, ..., -0.02043152,
         -0.02290535, -0.02374077]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a86d439b0>, (slice(13, 14, None), slice(1000, 2000, None), slice(7000, 8000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[        nan,         nan,         nan, ..., -5.09959078,
         -6.77587891, -8.5830431 ],
        [        nan,         nan,         nan, ..., -4.46573257,
         -5.96785164, -7.59919643],
        [        nan,         nan,         nan, ..., -3.80591321,
         -5.10741711, -6.53112078],
        ...,
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9de3ceb8>, (slice(21, 22, None), slice(3000, 4000, None), slice(7000, 8000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[-2.54669189e-02, -2.02293396e-02, -1.13296509e-02, ...,
                     nan,             nan,             nan],
        [-2.79083252e-02, -2.38056183e-02, -1.52835846e-02, ...,
                     nan,             nan,             nan],
        [-2.93636322e-02, -2.64015198e-02, -1.86443329e-02, ...,
                     nan,             nan,             nan],
        ...,
        [-1.34947586e+01,  1.00367918e+01,  8.12005615e+00, ...,
                     nan,             nan,             nan],
        [-1.27966661e+01, -1.48247538e+01,  8.71741295e+00, ...,
                     nan,             nan,             nan],
        [-1.19344149e+01,  1.13998575e+01,  9.53609657e+00, ...,
                     nan,             nan,             nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9e88eb70>, (slice(14, 15, None), slice(2000, 3000, None), slice(8000, 8354, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[-12.88468933, -13.85184002, -15.33917522, ...,   0.01908784,
           0.02328173,   0.02673787],
        [-13.50048447, -14.43394279, -15.8690443 , ...,   0.02901375,
           0.0335031 ,   0.03655751],
        [-14.1387701 , -15.03465652, -16.41175842, ...,   0.02016232,
           0.02293116,   0.02464538],
        ...,
        [         nan,          nan,          nan, ...,          nan,
                  nan,          nan],
        [         nan,          nan,          nan, ...,          nan,
                  nan,          nan],
        [         nan,          nan,          nan, ...,          nan,
                  nan,          nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9de87978>, (slice(6, 7, None), slice(1000, 2000, None), slice(0, 1000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9d22a438>, (slice(12, 13, None), slice(0, 1000, None), slice(7000, 8000, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - WARNING -  Compute Failed
Function:  store_chunk
args:      (array([[[14.34463406, 12.41923046, 10.56838989, ...,         nan,
                 nan,         nan],
        [15.50867176, 13.71144485, 12.00310993, ...,         nan,
                 nan,         nan],
        [16.71750832, 15.18995762, 13.62370491, ...,         nan,
                 nan,         nan],
        ...,
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan],
        [        nan,         nan,         nan, ...,         nan,
                 nan,         nan]]]), <xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x2b3a9eb4eef0>, (slice(12, 13, None), slice(3000, 4000, None), slice(8000, 8354, None)), None, False)
kwargs:    {}
Exception: CommClosedError('in <closed TCP>: Stream is closed')

distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:37378
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:33039'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:40004
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:39331
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:43781'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:45828
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:41548
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:32898
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:38075
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:42380
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:45517
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:42751
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:35993
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:42082
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:39211
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:44326'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:44958
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:43595
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:39830'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:42587
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:34302'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:36499'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:39139
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:40867'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:43587'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:45161'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:42174'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:46369'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:43984'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:34518'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:35373
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:38741'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:37819'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:43135
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:32853'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:33616'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:34958'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:41545'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:42931
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:46276
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:43011'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:43932'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.4:37359
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:32890
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:40397
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:46184
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:37849
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:36173
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:42943'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:33387'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:36525'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:46054'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:35390'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:35676
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:38205'
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.4:37359'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.8.171:34900
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.171:43142'
distributed.dask_worker - INFO - End worker
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
